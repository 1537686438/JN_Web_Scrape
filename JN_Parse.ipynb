{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "JN_url = \"https://www.jneurosci.org\"\n",
    "#authorList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the links with a href tag and a specific class\n",
    "#Return the content as a list of string\n",
    "def find_href(soup, clas):\n",
    "    data_list = soup.find_all('a', class_ = clas)\n",
    "    href_list = [tag['href'] for tag in data_list if tag.has_attr('href')]\n",
    "    return href_list\n",
    "\n",
    "#Get html of a link\n",
    "#Retrun the html as a beautifulsoup object\n",
    "def get_soup (short_url):\n",
    "    cur_url = '%s%s' % (JN_url, short_url)\n",
    "    cur_r = requests.get(cur_url)\n",
    "    cur_soup = BeautifulSoup(cur_r.content, \"html.parser\")\n",
    "    return cur_soup\n",
    "\n",
    "#Get the words in between two strings\n",
    "#Return a string\n",
    "def get_inBetween (string, start, end):\n",
    "    sub1 = start\n",
    "    sub2 = end\n",
    "    idx1 = string.index(sub1)\n",
    "    idx2 = string.index(sub2)\n",
    "    return string[idx1 + len(sub1) + 1: idx2]\n",
    "\n",
    "#Get the name of author from a sentence\n",
    "#Return author name as a string if successful, an empty string if not\n",
    "def get_name(string):\n",
    "    name = \"\"\n",
    "    if string.endswith(\"at \"):\n",
    "        if string.startswith(\"Correspo\"):\n",
    "            name = get_inBetween(string, \"to\", \" at\")\n",
    "        elif string.startswith (\"or\") or string.startswith(\" or\"):\n",
    "            name = get_inBetween(string, \"or\", \" at\")\n",
    "        elif string.startswith(\",\"):\n",
    "            name = get_inBetween(string, \",\", \" at\")\n",
    "        else:\n",
    "            name = string\n",
    "            print(\"get name failed\")\n",
    "    else:\n",
    "        name = string\n",
    "        print(\"get name failed\")\n",
    "    return name\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the title, abstract and author information of an article\n",
    "#Return the information as a dictonary, author information as a \n",
    "#nested dictionary matching author with emails\n",
    "def get_journal_info (j_info, j_full):\n",
    "\n",
    "#Get the article title\n",
    "    a_title = j_info.find('h1', class_ = \"highwire-cite-title\", id = \"page-title\")\n",
    "    title_text = \"\"\n",
    "    for string in a_title.strings:\n",
    "        title_text = title_text + string\n",
    "    print(\"processing:\", title_text)\n",
    "\n",
    "#Get the abstract of the article\n",
    "    abstract = j_full.find('div', class_ = \"section abstract\")\n",
    "    if abstract is not None:\n",
    "        abstract_text = \"\"\n",
    "        for string in abstract.strings:\n",
    "            abstract_text = abstract_text + string\n",
    "        abstract_text = abstract_text[8:]\n",
    "    else:\n",
    "        abstract_text = \"No abstract\"\n",
    "\n",
    "#Get the correpsondence author list\n",
    "    cor_class = j_info.find('li', class_ = \"corresp\")\n",
    "    corrsp_list =  []\n",
    "\n",
    "    #Create a list of author information from the raw html\n",
    "    for child in cor_class.descendants:\n",
    "        if isinstance(child, NavigableString):\n",
    "            corrsp_list.append(child)\n",
    "    #Remove the last item if it is a \".\"\n",
    "    if corrsp_list [-1] == \".\\n\":\n",
    "        corrsp_list = corrsp_list[:-1]\n",
    "    #print(corrsp_list)\n",
    "    corrsp_dict = {}\n",
    "    #Build the dictionary of author information\n",
    "    for item in corrsp_list:\n",
    "        cur_index =  corrsp_list.index(item)\n",
    "        if cur_index%2 == 0:\n",
    "            try:\n",
    "                cur_name = get_name(item)\n",
    "                cur_email = corrsp_list[cur_index + 1]\n",
    "                cur_email = cur_email.replace(\"{at}\", \"@\")\n",
    "                corrsp_dict[cur_name] = cur_email\n",
    "            except:\n",
    "                print(\"Email problem\")\n",
    "\n",
    "    \n",
    "    j_data = {\"Title\": title_text,\n",
    "              \"Abstract\" : abstract_text,\n",
    "              \"Correspondence \" : corrsp_dict}\n",
    "    \n",
    "    return j_data\n",
    "\n",
    "#Return a pd dataframe of the article information\n",
    "def to_df (dict):\n",
    "    df = pd.DataFrame(data=None)\n",
    "    corr = dict['Correspondence ']\n",
    "    key_list = list(corr.keys())\n",
    "    counter = 0\n",
    "    for name in corr:\n",
    "        if counter == 0:\n",
    "            df.at[counter, 'Title'] = dict['Title']\n",
    "            df.at[counter, 'Abstract'] = dict['Abstract']\n",
    "        df.at[counter, 'Author'] = key_list[counter]\n",
    "        df.at[counter, 'Email'] = corr[key_list[counter]]\n",
    "        counter += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.jneurosci.org/content/by/year\"\n",
    "#r = requests.get(URL)\n",
    "#print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the output diractory\n",
    "work_dir = os.getcwd()\n",
    "output_dir = os.path.join(work_dir, \"output\")\n",
    "os.makedirs(output_dir, exist_ok= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of link of the archive from the starting year to 2024\n",
    "#Ione asked for the past 10 year, so starting year should be 2014\n",
    "starting_year =  2023\n",
    "year_list_url = []\n",
    "while starting_year <= 2024:\n",
    "    cur_url = ''.join([URL, \"/\", str(starting_year)])\n",
    "    year_list_url.append(cur_url)\n",
    "    starting_year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the csv files for each yaer\n",
    "for url in year_list_url :\n",
    "    #Get the current year link and html object\n",
    "    cur_r = requests.get(url)\n",
    "    cur_year = url[-4:]\n",
    "    issue_soup = BeautifulSoup(cur_r.content, 'html.parser')\n",
    "    issue_href = find_href(issue_soup, 'hw-issue-meta-data')\n",
    "    output = []\n",
    "\n",
    "    #Go through every issue in cur_year\n",
    "    #Loop through the entire list instead of :2 to get everything\n",
    "    for link in issue_href[:2]:\n",
    "        print (\"Working on\", link)\n",
    "\n",
    "        #Find link to articles\n",
    "        article_html = get_soup(link)\n",
    "        article_href = find_href(article_html, 'highwire-cite-linked-title')\n",
    "        good_href = []\n",
    "        for href in article_href:\n",
    "            if href.startswith('%s%s'%(link, \"/\")) and not href.startswith('%s%s'%(link, \"/etwij\")):\n",
    "                good_href.append(href)\n",
    "\n",
    "        #Get a list of all journal info in the current issue\n",
    "        issue_info = []\n",
    "        for link in good_href:\n",
    "            #Get the beautifulsoup object needed to find information\n",
    "            j_info_link = j_info_link = '%s%s' % (link, \"/tab-article-info\")\n",
    "            j_info = get_soup(j_info_link)\n",
    "            j_full = get_soup(link)\n",
    "\n",
    "            #Add info to the list if author information is successfully extracted\n",
    "            if j_info.find('li', class_ = \"corresp\") is not None:\n",
    "                cur_j_data = get_journal_info(j_info, j_full)\n",
    "                issue_info.append(cur_j_data)\n",
    "\n",
    "        #Create a list of issue information dataframe\n",
    "        for article in issue_info:\n",
    "            cur_df = to_df(article)\n",
    "            output.append(cur_df)\n",
    "\n",
    "    #Print the result to csv\n",
    "    results = pd.concat(output)\n",
    "    file_name = f\"{cur_year}.csv\"\n",
    "    results.to_csv(os.path.join(output_dir, file_name), mode= 'w', index= False, encoding= 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
